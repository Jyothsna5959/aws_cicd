name: Deploy CSV from S3 to SF

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.8'

    - name: Install schemachange
      run: |
        pip install schemachange snowflake-connector-python

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    #Upload JSON to S3
    - name: Upload JSON to S3
      run: |
        aws s3 cp ./s3://drai-cicd-snf/datareadyai/inbound/

    #Deploy to Snowflake
    - name: Deploy to SF
      env:
        SF_ACCOUNT: ${{ secrets.SF_ACCOUNT }}
        SF_USER: ${{ secrets.SF_USERNAME }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SF_PASSWORD }}
        SF_ROLE: ${{ secrets.SF_ROLE }}
        SF_WAREHOUSE: ${{ secrets.SF_WAREHOUSE }}
        SF_DATABASE: ${{ secrets.SF_DATABASE }}
        SF_SCHEMA: ${{ secrets.SF_SCHEMA }}
      run: |
        schemachange \
          -a $SF_ACCOUNT \
          -u $SF_USER \
          -r $SF_ROLE \
          -w $SF_WAREHOUSE \
          -d $SF_DATABASE \
          -c $SF_DATABASE.SCHEMACHANGE.CHANGE_HISTORY \
          --create-change-history-table
